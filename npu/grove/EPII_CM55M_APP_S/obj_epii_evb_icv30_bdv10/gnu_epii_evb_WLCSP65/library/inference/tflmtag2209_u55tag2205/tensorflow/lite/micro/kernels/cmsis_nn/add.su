./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/op_macros.h:24:13:void AbortImpl()	8	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/cmsis_nn/add.cc:245:7:void* tflite::InitAdd(TfLiteContext*, const char*, size_t)	8	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/cmsis_nn/add.cc:250:14:TfLiteStatus tflite::PrepareAdd(TfLiteContext*, TfLiteNode*)	56	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/reference/process_broadcast_shapes.h:40:13:bool tflite::reference_ops::ProcessBroadcastShapes(const tflite::RuntimeShape&, const tflite::RuntimeShape&, tflite::ArithmeticParams*)	80	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/cmsis_nn/add.cc:346:20:TfLiteRegistration tflite::Register_ADD()	16	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/cmsis_nn/add.cc:350:20:TfLiteRegistration tflite::Register_ADD_INT8()	16	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/cmsis_nn/add.cc:354:20:TfLiteRegistration tflite::Register_ADD_INT16()	16	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/common.h:961:13:void tflite::NdArrayDescsForElementwiseBroadcast(const RuntimeShape&, const RuntimeShape&, NdArrayDesc<N>*, NdArrayDesc<N>*) [with int N = 4]	80	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/cmsis_nn/add.cc:124:14:TfLiteStatus tflite::{anonymous}::EvalAddQuantizedInt8(TfLiteContext*, TfLiteNode*, TfLiteAddParams*, const OpData*, const TfLiteEvalTensor*, const TfLiteEvalTensor*, TfLiteEvalTensor*)	704	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/cmsis_nn/add.cc:306:14:TfLiteStatus tflite::EvalAddInt8(TfLiteContext*, TfLiteNode*)	16	static
./library/inference/tflmtag2209_u55tag2205/tensorflow/lite/kernels/internal/reference/add.h:244:1:typename std::enable_if<tflite::is_small_integer<T>::value, void>::type tflite::reference_ops::BroadcastAdd4DSlow(const tflite::ArithmeticParams&, const tflite::RuntimeShape&, const T*, const tflite::RuntimeShape&, const T*, const tflite::RuntimeShape&, T*) [with T = short int]	336	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/cmsis_nn/add.cc:162:14:TfLiteStatus tflite::{anonymous}::EvalAddQuantizedInt16(TfLiteContext*, TfLiteNode*, TfLiteAddParams*, const OpData*, const TfLiteEvalTensor*, const TfLiteEvalTensor*, TfLiteEvalTensor*)	448	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/cmsis_nn/add.cc:279:14:TfLiteStatus tflite::EvalAdd(TfLiteContext*, TfLiteNode*)	392	static
library/inference/tflmtag2209_u55tag2205/tensorflow/lite/micro/kernels/cmsis_nn/add.cc:326:14:TfLiteStatus tflite::EvalAddInt16(TfLiteContext*, TfLiteNode*)	16	static
